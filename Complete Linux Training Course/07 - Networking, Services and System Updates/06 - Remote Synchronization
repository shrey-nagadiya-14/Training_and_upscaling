# rsync - Remote Synchronization Complete Guide

## Table of Contents
1. [What is rsync?](#what-is-rsync)
2. [How rsync Works](#how-rsync-works)
3. [Installation](#installation)
4. [Basic Syntax](#basic-syntax)
5. [Common Options](#common-options)
6. [Basic Examples](#basic-examples)
7. [Daily Use Cases](#daily-use-cases)
8. [Real-Life Scenarios](#real-life-scenarios)
9. [Advanced Techniques](#advanced-techniques)
10. [Best Practices](#best-practices)

---

## 1. What is rsync?

### Definition
- **rsync** stands for "Remote Synchronization"
- A fast and versatile command-line utility for synchronizing files and directories
- Works locally on the same computer or between local and remote systems
- Uses SSH protocol (port 22) for secure remote transfers
- Significantly faster than traditional tools like FTP, SCP, or CP

### Key Features
✅ Only transfers differences (delta transfer algorithm)
✅ Compares modification times and file sizes
✅ Preserves file permissions, ownership, timestamps
✅ Supports compression during transfer
✅ Can resume interrupted transfers
✅ Bandwidth limiting options
✅ Dry-run mode for testing
✅ Incremental backups
✅ Delete functionality for mirroring

### Why rsync is Better than SCP/FTP

rsync vs SCP:
- SCP: Copies entire file even if only 1 byte changed
- rsync: Only transfers the changed parts
- Example: 1GB file with 1MB change
  - SCP transfers: 1GB
  - rsync transfers: ~1MB

rsync vs FTP:
- FTP: No encryption, slower, no delta transfer
- rsync: Encrypted via SSH, faster, intelligent transfer

---

## 2. How rsync Works

### The rsync Algorithm

Step 1: Compare Files
Client (A) has file: 2M (2 MB)
Server (B) has file: 2M (2 MB)
rsync compares: modification time + size
Result: Files identical → Skip transfer

Step 2: Detect Changes
Client (A): File modified, now 8M
Server (B): Still has 8M
Client calculation: 8M - 2M = 6M changed
Result: Transfer only 6M (not entire 8M)

Step 3: Smart Synchronization
Client (A): File grew from 8M to 20M
Server (B): Has 8M
Client calculation: 20M - 8M = 12M new data
Result: Transfer only 12M

Visual Representation:
┌─────────────────────┐         SSH/rsync (Port 22)         ┌─────────────────────┐
│   Client = A        │────────────────────────────────────>│   Server = B        │
│   MyFirstLinuxVM    │                                      │   LinuxCentOS7      │
│                     │                                      │                     │
│   File: 2M ▢        │         Compare & Sync              │   File: 2M ▢        │
│   File: 8M ▢        │<────────────────────────────────────│   File: 8M ▢        │
│   File: 20M ▢       │    Only transfer differences        │   File: 20M ▢       │
└─────────────────────┘                                      └─────────────────────┘

### Delta Transfer Algorithm
1. rsync splits files into fixed-size blocks
2. Calculates checksums for each block
3. Compares checksums between source and destination
4. Only transfers blocks that differ
5. Reconstructs file at destination

Example:
Original file (Server): AAAA BBBB CCCC DDDD
Modified file (Client): AAAA XXXX CCCC YYYY
rsync transfers: XXXX and YYYY only (not AAAA and CCCC)

---

## 3. Installation

### Check if rsync is Already Installed
# Check rsync version
rsync --version

# Check if rsync is installed
which rsync
# Output: /usr/bin/rsync (if installed)

### Install rsync on CentOS/RHEL/Rocky Linux
# Install using yum
sudo yum install rsync -y

# Or using dnf (RHEL 8+)
sudo dnf install rsync -y

### Install rsync on Ubuntu/Debian
# Install using apt
sudo apt-get update
sudo apt-get install rsync -y

### Install rsync on macOS
# Already pre-installed, but to update:
brew install rsync

### Verify Installation
# Check version
rsync --version
# Output:
# rsync  version 3.2.3  protocol version 31
# Copyright (C) 1996-2020 by Andrew Tridgell, Wayne Davison, and others.

# Check rsync daemon status (if running as service)
systemctl status rsync

---

## 4. Basic Syntax

### Command Structure
rsync [OPTIONS] SOURCE DESTINATION

Components:
- OPTIONS: Flags that control rsync behavior
- SOURCE: File or directory to copy from
- DESTINATION: Where to copy to

### Local Syntax
# Copy within same machine
rsync [options] /path/to/source /path/to/destination

### Remote Syntax (Push to Remote)
# Copy from local to remote
rsync [options] /local/path user@remote-host:/remote/path

### Remote Syntax (Pull from Remote)
# Copy from remote to local
rsync [options] user@remote-host:/remote/path /local/path

### Remote to Remote
# Copy between two remote hosts
rsync [options] user1@host1:/path user2@host2:/path

---

## 5. Common Options

### Essential Options

| Option | Full Form | Description | Example |
|--------|-----------|-------------|---------|
| -v | --verbose | Verbose output (show what's being done) | rsync -v source dest |
| -r | --recursive | Copy directories recursively | rsync -r /dir /backup |
| -a | --archive | Archive mode (preserves everything) | rsync -a /dir /backup |
| -z | --compress | Compress data during transfer | rsync -z file remote:/ |
| -h | --human-readable | Human-readable file sizes | rsync -h source dest |
| -P | --progress | Show progress during transfer | rsync -P file remote:/ |
| -n | --dry-run | Test run (don't actually copy) | rsync -n -av source dest |
| -u | --update | Skip files newer on destination | rsync -u source dest |
| -l | --links | Copy symlinks as symlinks | rsync -l source dest |
| -p | --perms | Preserve permissions | rsync -p source dest |
| -t | --times | Preserve modification times | rsync -t source dest |
| -g | --group | Preserve group ownership | rsync -g source dest |
| -o | --owner | Preserve owner | rsync -o source dest |
| -D | --devices | Preserve device files | rsync -D source dest |

### Archive Mode (-a) Breakdown
-a is equivalent to: -rlptgoD
- r: recursive
- l: copy symlinks as symlinks
- p: preserve permissions
- t: preserve modification times
- g: preserve group
- o: preserve owner
- D: preserve device files

Usage:
rsync -a /source /destination
# Same as:
rsync -rlptgoD /source /destination

### Advanced Options

| Option | Description | Example |
|--------|-------------|---------|
| --delete | Delete files in dest that don't exist in source | rsync -a --delete source/ dest/ |
| --exclude | Exclude files/directories | rsync -a --exclude='*.log' source/ dest/ |
| --include | Include specific files | rsync -a --include='*.txt' source/ dest/ |
| --bwlimit | Limit bandwidth (KB/s) | rsync --bwlimit=1000 source dest |
| --partial | Keep partially transferred files | rsync --partial source dest |
| --progress | Show progress bar | rsync --progress source dest |
| --stats | Show transfer statistics | rsync --stats source dest |
| -e | Specify remote shell | rsync -e 'ssh -p 2222' source dest |
| --remove-source-files | Delete source files after transfer | rsync --remove-source-files src dst |
| --max-size | Don't transfer files larger than SIZE | rsync --max-size='100M' src dst |
| --min-size | Don't transfer files smaller than SIZE | rsync --min-size='1K' src dst |

---

## 6. Basic Examples (From Slides)

### Example 1: Create a Backup Archive (Local)
# Step 1: Create a tar archive of home directory
tar cvf backup.tar .

# Step 2: Create backup directory
mkdir /tmp/backups

# Step 3: Sync tar file to backup directory with compression
rsync -zvh backup.tar /tmp/backups/

# Explanation:
# -z: Compress during transfer
# -v: Verbose (show what's happening)
# -h: Human-readable sizes

# Output:
# backup.tar
#          127.34M 100%    0.00kB/s    0:00:01 (xfr#1, to-chk=0/1)
# sent 127.56M bytes  received 35 bytes  85.04M bytes/sec
# total size is 127.34M  speedup is 1.00

### Example 2: Sync a Directory (Local)
# Sync entire home directory to backup location
rsync -azvh /home/iafzal /tmp/backups/

# Explanation:
# -a: Archive mode (preserves permissions, timestamps, etc.)
# -z: Compress
# -v: Verbose
# -h: Human-readable

# Output:
# sending incremental file list
# iafzal/
# iafzal/.bash_history
# iafzal/.bashrc
# iafzal/documents/file1.txt
# iafzal/documents/file2.pdf
# ...
# sent 45.67M bytes  received 1.23K bytes  30.45M bytes/sec
# total size is 45.65M  speedup is 1.00

### Example 3: Sync File to Remote Machine
# Step 1: Create backup directory on remote server
# (First SSH to remote server and create directory)
ssh iafzal@192.168.1.x
mkdir /tmp/backups
exit

# Step 2: Sync file from local to remote
rsync -avz backup.tar iafzal@192.168.1.x:/tmp/backups

# Explanation:
# This pushes backup.tar from local machine to remote server
# -a: Archive mode
# -v: Verbose
# -z: Compress during transfer
# iafzal@192.168.1.x: Remote user@host
# :/tmp/backups: Remote destination path

# You will be prompted for password:
# iafzal@192.168.1.x's password: 

# Output:
# sending incremental file list
# backup.tar
#       127.34M 100%   45.23MB/s    0:00:02 (xfr#1, to-chk=0/1)
# sent 127.56M bytes  received 35 bytes  25.51M bytes/sec
# total size is 127.34M  speedup is 1.00

### Example 4: Sync File from Remote Machine
# Step 1: Create a test file on remote server
# (SSH to remote and create file)
ssh iafzal@192.168.1.x
touch serverfile
exit

# Step 2: Pull file from remote to local
rsync -avzh iafzal@192.168.1.x:/home/iafzal/serverfile /tmp/backups

# Explanation:
# This pulls serverfile from remote server to local machine
# iafzal@192.168.1.x:/home/iafzal/serverfile: Remote source
# /tmp/backups: Local destination

# Output:
# receiving incremental file list
# serverfile
#              0 100%    0.00kB/s    0:00:00 (xfr#1, to-chk=0/1)
# sent 43 bytes  received 156 bytes  132.67 bytes/sec
# total size is 0  speedup is 0.00

---

## 7. Daily Use Cases

### Use Case 1: Daily Backup of Critical Files

Scenario: You need to backup important documents daily to external drive

# Backup documents to external drive
rsync -avzh --progress /home/username/Documents/ /mnt/external-drive/backups/Documents/

# Explanation:
# -a: Preserves all file attributes
# -v: Shows what's being copied
# -z: Compresses during transfer
# -h: Human-readable sizes
# --progress: Shows progress bar

# Output:
# sending incremental file list
# ./
# report-2025.pdf
#       2.34M 100%    1.23MB/s    0:00:01 (xfr#1, to-chk=23/145)
# invoice-jan.xlsx
#     456.78K 100%  234.56KB/s    0:00:01 (xfr#2, to-chk=22/145)
# 
# sent 45.67M bytes  received 1.89K bytes  3.04M bytes/sec
# total size is 45.65M  speedup is 1.00

Real-Life Benefits:
- First run: Copies all files (may take time)
- Subsequent runs: Only copies changed files (very fast)
- Safe: Original files remain untouched
- Efficient: No duplicate data transfer

### Use Case 2: Sync Website Files to Production Server

Scenario: You're a web developer deploying website updates

# Sync local website to production server
rsync -avz --delete /var/www/mywebsite/ user@production-server:/var/www/html/

# Explanation:
# --delete: Removes files from server that don't exist locally
# This ensures production server is exact mirror of local

# With exclude patterns (don't sync certain files):
rsync -avz --delete \
  --exclude='*.log' \
  --exclude='cache/*' \
  --exclude='.git' \
  /var/www/mywebsite/ user@production-server:/var/www/html/

# Output:
# sending incremental file list
# deleting cache/old-file.tmp
# index.html
#      12.34K 100%   10.45KB/s    0:00:01 (xfr#1, to-chk=45/234)
# css/style.css
#       3.45K 100%    2.98KB/s    0:00:00 (xfr#2, to-chk=44/234)
# js/app.js
#      23.45K 100%   18.76KB/s    0:00:01 (xfr#3, to-chk=43/234)
# 
# sent 234.56K bytes  received 1.23K bytes  47.16K bytes/sec
# total size is 12.34M  speedup is 52.36

Real-Life Benefits:
- Only modified files are uploaded
- Deployment takes seconds, not minutes
- --delete ensures no orphaned files on server
- Can rollback by syncing previous version

### Use Case 3: Automated Server Backups

Scenario: Daily backup of production database and configs

# Create backup script: /usr/local/bin/daily-backup.sh
#!/bin/bash

# Variables
BACKUP_SERVER="backup@backup-server.com"
SOURCE_DIR="/var/lib/mysql"
CONFIG_DIR="/etc"
DEST_DIR="/backups/production/$(date +%Y-%m-%d)"

# Create destination directory on backup server
ssh $BACKUP_SERVER "mkdir -p $DEST_DIR"

# Backup database files
echo "Backing up database..."
rsync -avz --delete \
  --exclude='*.log' \
  $SOURCE_DIR/ $BACKUP_SERVER:$DEST_DIR/mysql/

# Backup configuration files
echo "Backing up configs..."
rsync -avz \
  $CONFIG_DIR/ $BACKUP_SERVER:$DEST_DIR/configs/

# Log completion
echo "Backup completed at $(date)" >> /var/log/backup.log

# Add to crontab (runs daily at 2 AM)
# 0 2 * * * /usr/local/bin/daily-backup.sh

Real-Life Benefits:
- Automated, no manual intervention
- Dated backups for point-in-time recovery
- Only changed data is transferred
- Low bandwidth usage
- Can restore to any previous date

### Use Case 4: Photo Library Sync Between Devices

Scenario: Keep photo library synchronized across multiple computers

# Sync photos from laptop to desktop
rsync -avzh --progress \
  ~/Pictures/ user@desktop-pc:/home/user/Pictures/

# With checksums (ensure exact copies):
rsync -avzh --checksum --progress \
  ~/Pictures/ user@desktop-pc:/home/user/Pictures/

# Bidirectional sync (sync both ways):
# First: Push local changes to remote
rsync -avzh --update ~/Pictures/ user@desktop-pc:/home/user/Pictures/

# Second: Pull remote changes to local
rsync -avzh --update user@desktop-pc:/home/user/Pictures/ ~/Pictures/

Real-Life Example:
You have:
- Laptop: 5,000 photos (150 GB)
- Desktop: 4,800 photos (145 GB)

First sync: Transfers 200 new photos (5 GB) - takes 10 minutes
Daily syncs: Only new photos - takes seconds

Real-Life Benefits:
- No need for cloud storage subscription
- Full control of your data
- Fast synchronization
- Works on local network (very fast) or over internet

### Use Case 5: Development Environment Sync

Scenario: Keep development code synchronized across multiple machines

# Sync development project from work PC to home PC
rsync -avz --exclude='.git' --exclude='node_modules' \
  ~/projects/myapp/ user@home-pc:~/projects/myapp/

# More comprehensive exclude list:
rsync -avz \
  --exclude='.git' \
  --exclude='node_modules' \
  --exclude='*.log' \
  --exclude='dist/' \
  --exclude='build/' \
  --exclude='.env.local' \
  ~/projects/myapp/ user@home-pc:~/projects/myapp/

# Dry run first (see what would be copied):
rsync -avzn --exclude='.git' --exclude='node_modules' \
  ~/projects/myapp/ user@home-pc:~/projects/myapp/

Real-Life Benefits:
- Continue work from different locations
- No need to commit unfinished code to git
- Excludes unnecessary files (node_modules, builds)
- Faster than git clone for large projects
- Preserves file timestamps and permissions

### Use Case 6: Log File Collection from Multiple Servers

Scenario: Collect logs from multiple servers for analysis

# Create collection script
#!/bin/bash

SERVERS=(
  "web1.company.com"
  "web2.company.com"
  "app1.company.com"
  "db1.company.com"
)

LOG_DIR="/var/log"
DEST_DIR="/central-logs/$(date +%Y-%m-%d)"

mkdir -p $DEST_DIR

for server in "${SERVERS[@]}"; do
  echo "Collecting logs from $server..."
  rsync -avz --include='*.log' --exclude='*' \
    user@$server:$LOG_DIR/ $DEST_DIR/$server/
done

echo "Log collection completed"

Real-Life Benefits:
- Centralized log analysis
- Quick troubleshooting
- Compliance and audit trails
- Only transfers new log entries
- Can search across all servers

### Use Case 7: Mirror Website for Offline Access

Scenario: Create offline mirror of website for offline browsing or testing

# Mirror website content
rsync -avz --delete \
  webmaster@production-server:/var/www/html/ \
  /home/user/website-mirror/

# Access offline:
cd /home/user/website-mirror/
python3 -m http.server 8080
# Open browser: http://localhost:8080

Real-Life Benefits:
- Test changes locally before deploying
- Offline access to documentation sites
- Faster development (no network latency)
- Safe testing environment

### Use Case 8: Incremental Backup Strategy

Scenario: Create space-efficient incremental backups

# Full backup (Day 1)
rsync -avz --delete /home/user/ /backups/full/

# Incremental backup (Day 2 onwards)
rsync -avz --delete --link-dest=/backups/full/ \
  /home/user/ /backups/incremental-day2/

# Incremental backup (Day 3)
rsync -avz --delete --link-dest=/backups/incremental-day2/ \
  /home/user/ /backups/incremental-day3/

# How it works:
# --link-dest: Creates hard links for unchanged files
# Only changed files consume additional disk space
# Unchanged files point to previous backup

Example:
Day 1 full backup: 100 GB
Day 2 incremental: 2 GB (only changed files)
Day 3 incremental: 1.5 GB (only changed files)
Total space used: 103.5 GB (not 303.5 GB!)

Real-Life Benefits:
- Space-efficient backups
- Each backup appears as full backup
- Quick recovery (no need to apply multiple increments)
- Can keep many backup versions

---

## 8. Real-Life Scenarios

### Scenario 1: "I Need to Transfer 500GB to Remote Server"

Problem: You have 500GB of video files to transfer to remote server

Bad approach (using SCP):
scp -r /videos/ user@remote-server:/storage/
# Takes: 6-8 hours depending on connection
# If interrupted: Starts from beginning!

Good approach (using rsync):
rsync -avzh --progress --partial \
  /videos/ user@remote-server:/storage/videos/

# Advantages:
# --partial: Keeps partially transferred files
# --progress: Shows progress for each file
# If interrupted: Resume from where it stopped!

# Resume after interruption:
rsync -avzh --progress --partial \
  /videos/ user@remote-server:/storage/videos/
# Continues from last file, doesn't retransfer completed files

# Even better with compression:
rsync -avzh --progress --partial --compress-level=9 \
  /videos/ user@remote-server:/storage/videos/

Real Results:
- First transfer: 500GB (takes 6 hours)
- Connection drops at 400GB
- Resume: Continues from 400GB (takes 1.2 hours)
- Total time: 7.2 hours vs 12+ hours with repeated SCP attempts

### Scenario 2: "Update Production Without Downtime"

Problem: Deploy website update with minimal downtime

Strategy: Blue-Green deployment using rsync

# Step 1: Sync to staging directory (site still running)
rsync -avz --delete /local/website/ user@server:/var/www/staging/

# Step 2: Test staging
curl http://server/staging/
# Test all functionality

# Step 3: Quick atomic switch
ssh user@server 'mv /var/www/html /var/www/old && mv /var/www/staging /var/www/html'

# Step 4: If issues, quick rollback
ssh user@server 'mv /var/www/html /var/www/staging && mv /var/www/old /var/www/html'

Downtime analysis:
- Traditional upload: 5-10 minutes downtime
- rsync with staging: <1 second downtime (just the mv command)

Real-Life Benefits:
- Near-zero downtime
- Quick rollback capability
- Safe deployment process
- Happy customers!

### Scenario 3: "Bandwidth is Limited and Expensive"

Problem: Syncing over metered connection or slow link

# Limit bandwidth to 500 KB/s
rsync -avz --bwlimit=500 /large-files/ user@remote-server:/backup/

# Schedule transfer during off-peak hours (via cron)
# Run at 2 AM when bandwidth is cheaper
0 2 * * * rsync -avz --bwlimit=1000 /data/ backup-server:/backups/

# Compress more aggressively for text files
rsync -avz --compress-level=9 /documents/ user@remote-server:/docs/

# Skip large files (transfer separately)
rsync -avz --max-size='100M' /mixed-files/ user@remote-server:/backup/

Bandwidth comparison:
Without --bwlimit:
- Uses: Full bandwidth (saturates connection)
- Other applications: Suffer
- Transfer time: 2 hours
- Cost: High (if metered)

With --bwlimit=500:
- Uses: Maximum 500 KB/s
- Other applications: Work fine
- Transfer time: 4 hours
- Cost: Lower
- Overall: Much better user experience

### Scenario 4: "Disaster Recovery - Server Crashed!"

Problem: Production server crashed, need to restore from backup

# Scenario: Database server crashed

# Step 1: Spin up new server (same OS, same paths)

# Step 2: Restore everything from backup
rsync -avz --progress backup-server:/backups/db-server/2025-11-20/ /

# Output shows what's being restored:
# receiving incremental file list
# ./
# etc/mysql/my.cnf
# var/lib/mysql/database1/table1.frm
# var/lib/mysql/database1/table1.ibd
# ...

# Step 3: Fix permissions if needed
chown -R mysql:mysql /var/lib/mysql

# Step 4: Start services
systemctl start mysql

# Step 5: Verify
mysql -u root -p -e "SHOW DATABASES;"

Recovery time:
- Without rsync: Manual restore, 2-4 hours
- With rsync: Automated restore, 30 minutes
- Downtime reduced by 75%!

Real-Life Benefits:
- Fast disaster recovery
- Tested restore process
- Confidence in backups
- Minimal business impact

### Scenario 5: "Need to Sync 10,000 Small Config Files"

Problem: Many small files (configs, scripts) need frequent syncing

Challenge: Small files are slow to transfer individually

# Bad approach (many separate transfers):
for file in /configs/*; do
  scp $file user@remote-server:/configs/
done
# Very slow! Each file has connection overhead

# Good approach (rsync batch transfer):
rsync -avz /configs/ user@remote-server:/configs/

# Even better (with whole-file transfer for small files):
rsync -avz -W /configs/ user@remote-server:/configs/

# Best (archive to reduce file count, then transfer):
tar czf configs.tar.gz /configs/
rsync -avz configs.tar.gz user@remote-server:/tmp/
ssh user@remote-server 'tar xzf /tmp/configs.tar.gz -C /'

Performance comparison:
Individual SCP: 10,000 files, 30 minutes
rsync: 10,000 files, 2 minutes
tar + rsync: 1 file, 30 seconds

### Scenario 6: "Multiple Team Members Need Same Files"

Problem: Team of 5 developers need 50GB development environment

Traditional approach:
Each person downloads from server: 5 × 50GB = 250GB transferred

Smart approach (rsync chain):
1. Person A downloads from server: 50GB
2. Person B syncs from Person A (local network): 50GB at LAN speed
3. Person C syncs from Person B (local network): 50GB at LAN speed
4. And so on...

# Person A (downloads from server)
rsync -avzh --progress server:/dev-environment/ ~/dev-env/

# Person B (syncs from Person A on local network)
rsync -avzh --progress personA-pc:~/dev-env/ ~/dev-env/
# Much faster! LAN speeds (100MB/s vs 10MB/s from internet)

# Person C (syncs from Person B)
rsync -avzh --progress personB-pc:~/dev-env/ ~/dev-env/

Benefits:
- Total internet bandwidth used: 50GB (not 250GB)
- Faster for everyone (except Person A)
- Lower costs if bandwidth is metered
- More efficient use of resources

### Scenario 7: "Code Review - Compare Directories"

Problem: Need to see what changed between two versions

# Dry run to see differences
rsync -avzn --delete old-version/ new-version/

# Output shows what would change:
# deleting removed-file.txt
# sending incremental file list
# modified-file.py
# new-file.js
# 
# sent 12.34K bytes  received 234 bytes  8.37K bytes/sec
# total size is 45.67M  speedup is 3,632.45 (DRY RUN)

# See only list of changed files
rsync -avzn --itemize-changes old-version/ new-version/

# Output format:
# >f+++++++++ new-file.js        (new file)
# >f.st...... modified-file.py   (size/time changed)
# *deleting   removed-file.txt   (will be deleted)

Real-Life Usage:
- Pre-deployment verification
- Code review assistance
- Detecting unauthorized changes
- Audit trail

### Scenario 8: "Smart Home Backup Strategy"

Problem: Backup family photos, documents, videos efficiently

Setup:
- Laptop: 200GB (photos, documents, videos)
- External Drive 1: Main backup
- External Drive 2: Offsite backup (stored at relative's house)
- NAS: Network storage

# Weekly backup to External Drive 1
rsync -avzh --delete --progress \
  /home/user/ /media/external-drive-1/backups/

# Monthly backup to External Drive 2 (take to relative's house)
rsync -avzh --delete --progress \
  /media/external-drive-1/backups/ /media/external-drive-2/backups/

# Daily backup of important docs to NAS
rsync -avzh --delete --progress \
  --include='Documents/***' \
  --include='Pictures/***' \
  --exclude='*' \
  /home/user/ nas-server:/backups/user/

Backup schedule:
- Daily: Critical files to NAS (5 minutes)
- Weekly: Full backup to External Drive 1 (30 minutes)
- Monthly: Clone to External Drive 2 (30 minutes)

Result:
- 3-2-1 backup strategy (3 copies, 2 media types, 1 offsite)
- Automated and reliable
- Protected against hardware failure, theft, disaster
- Peace of mind!

---

## 9. Advanced Techniques

### Technique 1: Using rsync with SSH Keys (No Password Prompts)

Problem: Manual password entry prevents automation

Solution: SSH key-based authentication

# Step 1: Generate SSH key pair (on source machine)
ssh-keygen -t rsa -b 4096 -C "backup-automation"
# Press Enter for default location (/home/user/.ssh/id_rsa)
# Optional: Set passphrase or leave empty for automation

# Step 2: Copy public key to remote server
ssh-copy-id user@remote-server
# Enter password one last time

# Step 3: Test passwordless login
ssh user@remote-server
# Should login without password prompt!

# Step 4: Now rsync works without password
rsync -avz /data/ user@remote-server:/backup/
# No password prompt!

# Step 5: Automate with cron
crontab -e
# Add:
0 2 * * * rsync -avz /data/ user@remote-server:/backup/ >> /var/log/backup.log 2>&1

### Technique 2: Excluding Files with Patterns

# Exclude specific file types
rsync -avz --exclude='*.log' --exclude='*.tmp' /source/ /destination/

# Exclude multiple patterns
rsync -avz \
  --exclude='*.log' \
  --exclude='*.tmp' \
  --exclude='cache/' \
  --exclude='temp/' \
  --exclude='.git/' \
  /source/ /destination/

# Use exclude file (better for many patterns)
# Create file: exclude-list.txt
# Contents:
# *.log
# *.tmp
# cache/
# temp/
# .git/
# node_modules/
# *.swp
# .DS_Store

# Use exclude file:
rsync -avz --exclude-from='exclude-list.txt' /source/ /destination/

# Combine exclude and include
rsync -avz \
  --include='*.txt' \
  --include='*.pdf' \
  --exclude='*' \
  /documents/ /backup/
# This copies ONLY .txt and .pdf files

### Technique 3: Bandwidth Throttling

# Limit to 1000 KB/s (1 MB/s)
rsync -avz --bwlimit=1000 /large-files/ user@remote-server:/backup/

# Very slow connection? Limit to 100 KB/s
rsync -avz --bwlimit=100 /files/ user@remote-server:/backup/

# Monitor bandwidth usage during transfer
rsync -avz --progress --bwlimit=500 /files/ user@remote-server:/backup/

# Dynamic bandwidth limiting (different times)
# Fast during night, slow during day
HOUR=$(date +%H)
if [ $HOUR -ge 22 ] || [ $HOUR -le 6 ]; then
  BWLIMIT=0  # No limit at night
else
  BWLIMIT=500  # Limit during day
fi
rsync -avz --bwlimit=$BWLIMIT /data/ user@remote-server:/backup/

### Technique 4: Dry Run (Test Before Actual Transfer)

# See what would be transferred without actually doing it
rsync -avzn /source/ /destination/
# -n or --dry-run

# More verbose dry run
rsync -avzn --itemize-changes /source/ /destination/

# Output interpretation:
# >f+++++++++ some-new-file.txt       # Would be created
# >f.st...... modified-file.txt       # Would be updated (size/time changed)
# *deleting   old-file.txt            # Would be deleted (if using --delete)

# Save dry run output for review
rsync -avzn --delete /source/ /destination/ > dry-run-report.txt

# Review and then execute if looks good
cat dry-run-report.txt
# If OK, run without -n
rsync -avz --delete /source/ /destination/

### Technique 5: Comparing Directories

# Find differences between two directories
rsync -avzn --delete /dir1/ /dir2/

# More detailed comparison
rsync -avzn --delete --itemize-changes /dir1/ /dir2/

# Create comparison script
#!/bin/bash
echo "=== Files only in dir1 (would be copied to dir2) ==="
rsync -avzn --delete /dir1/ /dir2/ | grep "^>f"

echo "=== Files only in dir2 (would be deleted) ==="
rsync -avzn --delete /dir1/ /dir2/ | grep "^*deleting"

echo "=== Modified files ==="
rsync -avzn --delete --itemize-changes /dir1/ /dir2/ | grep "^>f\.st"

### Technique 6: Transfer with Checksums (Verify Integrity)

# Default: rsync compares size and modification time
rsync -avz /source/ /destination/

# With checksums: rsync calculates MD5 for each file
rsync -avz --checksum /source/ /destination/

# When to use --checksum:
# 1. Critical data (financial records, backups)
# 2. Suspect file corruption
# 3. Need to verify exact copies
# 4. Files modified without timestamp change

# Note: --checksum is slower (reads entire file)
# Without checksum: Instant comparison
# With checksum: Must read and hash entire file

# Example use case:
# Verify backup integrity
rsync -avz --checksum --dry-run /original/ /backup/
# If output shows files, they differ even though size/time match

### Technique 7: Syncing to Multiple Destinations

# Sync to multiple servers (loop)
SERVERS=(
  "backup1.company.com"
  "backup2.company.com"
  "backup3.company.com"
)

for server in "${SERVERS[@]}"; do
  echo "Syncing to $server..."
  rsync -avz /data/ user@$server:/backups/ || echo "Failed: $server"
done

# Parallel syncing (faster, uses more bandwidth)
for server in "${SERVERS[@]}"; do
  rsync -avz /data/ user@$server:/backups/ &
done
wait  # Wait for all background jobs to complete

# Using GNU parallel (if installed)
parallel rsync -avz /data/ user@{}:/backups/ ::: "${SERVERS[@]}"

### Technique 8: Atomic Directory Sync (Staging Method)

# Problem: Don't want partial sync visible to users
# Solution: Sync to temporary location, then atomically move

# Step 1: Sync to staging directory
rsync -avz --delete /local/website/ user@server:/var/www/staging/

# Step 2: Atomic swap (very fast, single operation)
ssh user@server 'mv /var/www/html /var/www/old && mv /var/www/staging /var/www/html'

# Step 3: Verify
curl http://server/

# Step 4: Clean up old version
ssh user@server 'rm -rf /var/www/old'

# Or rollback if issues:
ssh user@server 'mv /var/www/html /var/www/staging && mv /var/www/old /var/www/html'

### Technique 9: Incremental Backups with Hard Links

# Full backup
rsync -avz /home/user/ /backups/2025-11-20/

# Next day: Incremental (hard links unchanged files)
rsync -avz --link-dest=/backups/2025-11-20/ \
  /home/user/ /backups/2025-11-21/

# Day after: Reference previous incremental
rsync -avz --link-dest=/backups/2025-11-21/ \
  /home/user/ /backups/2025-11-22/

# How it works:
# /backups/2025-11-20/: 100 GB (full backup)
# /backups/2025-11-21/: 2 GB new data + hard links to unchanged files
# /backups/2025-11-22/: 1.5 GB new data + hard links to unchanged files
# Total disk space: 103.5 GB
# But each directory appears as complete 100+ GB backup!

# Automated script:
#!/bin/bash
CURRENT=$(date +%Y-%m-%d)
PREVIOUS=$(date -d "yesterday" +%Y-%m-%d)

if [ -d "/backups/$PREVIOUS" ]; then
  rsync -avz --link-dest="/backups/$PREVIOUS/" \
    /home/user/ "/backups/$CURRENT/"
else
  rsync -avz /home/user/ "/backups/$CURRENT/"
fi

### Technique 10: Resuming Interrupted Transfers

# Problem: Large transfer interrupted
# Solution: Use --partial flag

# Original transfer (interrupted)
rsync -avz --progress large-file.iso user@remote-server:/downloads/
# Connection lost at 60%...

# Resume transfer
rsync -avz --progress --partial large-file.iso user@remote-server:/downloads/
# Continues from 60%!

# Even better: Combine with --append-verify
rsync -avz --progress --partial --append-verify \
  large-file.iso user@remote-server:/downloads/

# For directories:
rsync -avz --progress --partial /large-directory/ user@remote-server:/backup/

# Short form: -P combines --partial and --progress
rsync -avzP /source/ user@remote-server:/destination/

---

## 10. Best Practices

### Best Practice 1: Always Test with Dry Run First

# Before running any rsync command with --delete, test it!
rsync -avzn --delete /source/ /destination/

# Review output carefully
# Look for unexpected deletions
# Verify paths are correct

# Only then run actual command
rsync -avz --delete /source/ /destination/

Why this matters:
# Wrong:
rsync -avz --delete /important-files /backup/
# Deletes everything in /backup/ except "important-files" file!

# Correct:
rsync -avz --delete /important-files/ /backup/
# The trailing slash matters!

### Best Practice 2: Trailing Slash Matters!

# Without trailing slash on source:
rsync -avz /source /destination/
# Creates: /destination/source/
# Result: /destination/source/file1.txt

# With trailing slash on source:
rsync -avz /source/ /destination/
# Syncs contents directly
# Result: /destination/file1.txt

# Remember:
# /source  = "copy the folder itself"
# /source/ = "copy the contents of the folder"

Examples:
rsync -avz /home/user /backup/
# Creates: /backup/user/

rsync -avz /home/user/ /backup/
# Creates: /backup/ (with contents of user/)

### Best Practice 3: Use Archive Mode by Default

# Bad:
rsync -r /source/ /destination/
# Only copies files recursively
# Loses permissions, ownership, timestamps

# Good:
rsync -a /source/ /destination/
# Preserves everything: permissions, ownership, timestamps, symlinks

# -a is equivalent to: -rlptgoD
# r: recursive
# l: links (copy symlinks as symlinks)
# p: permissions
# t: times (modification times)
# g: group
# o: owner
# D: devices and special files

### Best Practice 4: Log Everything

# Log to file
rsync -avz /source/ /destination/ >> /var/log/rsync-backup.log 2>&1

# Log with timestamp
echo "$(date): Starting backup" >> /var/log/rsync-backup.log
rsync -avz /source/ /destination/ >> /var/log/rsync-backup.log 2>&1
echo "$(date): Backup completed" >> /var/log/rsync-backup.log

# Rotate logs
#!/bin/bash
LOG_FILE="/var/log/rsync-backup.log"
MAX_SIZE=10485760  # 10MB

if [ -f "$LOG_FILE" ] && [ $(stat -f%z "$LOG_FILE") -gt $MAX_SIZE ]; then
  mv "$LOG_FILE" "$LOG_FILE.old"
  gzip "$LOG_FILE.old"
fi

rsync -avz /source/ /destination/ >> "$LOG_FILE" 2>&1

### Best Practice 5: Monitor and Alert on Failures

# Wrapper script with error handling
#!/bin/bash

LOG_FILE="/var/log/rsync-backup.log"
ADMIN_EMAIL="admin@company.com"

echo "$(date): Starting backup" >> "$LOG_FILE"

rsync -avz /important-data/ backup-server:/backups/ >> "$LOG_FILE" 2>&1

if [ $? -eq 0 ]; then
  echo "$(date): Backup successful" >> "$LOG_FILE"
else
  echo "$(date): Backup FAILED!" >> "$LOG_FILE"
  echo "Backup failed at $(date). Check $LOG_FILE for details." | \
    mail -s "BACKUP FAILURE ALERT" "$ADMIN_EMAIL"
  exit 1
fi

### Best Practice 6: Use Configuration Files for Complex Syncs

# Create: ~/.rsync-exclude
*.log
*.tmp
cache/
temp/
.git/
node_modules/
.DS_Store
Thumbs.db
*.swp

# Create: ~/rsync-backup.conf
# Source directories
/home/user/Documents
/home/user/Pictures
/home/user/Videos
/etc/

# Use in script:
rsync -avz --exclude-from=~/.rsync-exclude \
  --files-from=~/rsync-backup.conf \
  / backup-server:/backups/

### Best Practice 7: Set Timeouts for Remote Operations

# Prevent hanging on network issues
rsync -avz --timeout=300 /source/ user@remote-server:/dest/
# Timeout after 300 seconds (5 minutes) of no data transfer

# Connection timeout
rsync -avz --contimeout=30 /source/ user@remote-server:/dest/
# Timeout after 30 seconds if can't establish connection

# Both:
rsync -avz --timeout=300 --contimeout=30 \
  /source/ user@remote-server:/dest/

### Best Practice 8: Verify Backups Regularly

# Regular verification script (run weekly)
#!/bin/bash

echo "Verifying backup integrity..."

# Compare source and backup
rsync -avzn --checksum --delete /source/ /backup/ > /tmp/verify.txt

# Check if any differences found
if [ -s /tmp/verify.txt ]; then
  echo "WARNING: Backup verification found differences!"
  cat /tmp/verify.txt | mail -s "Backup Verification Alert" admin@company.com
else
  echo "Backup verification successful - no differences found"
fi

# Test restore (sample files)
mkdir -p /tmp/restore-test
rsync -avz /backup/sample-file.txt /tmp/restore-test/
diff /source/sample-file.txt /tmp/restore-test/sample-file.txt
if [ $? -eq 0 ]; then
  echo "Restore test successful"
else
  echo "ERROR: Restore test failed!"
fi

### Best Practice 9: Document Your rsync Commands

# Bad:
rsync -avz --delete /data/ server:/backup/
# What does this backup? When does it run? Who maintains it?

# Good: Create documented backup script
#!/bin/bash
# Backup Script for Production Database
# Purpose: Daily backup of /data/ to remote backup server
# Schedule: Runs daily at 2 AM via cron
# Maintainer: admin@company.com
# Last modified: 2025-11-20

SOURCE="/data/"
DEST="backup-server:/backups/daily/"
LOG="/var/log/backup.log"
EXCLUDE="/etc/backup-exclude.conf"

echo "========================================" >> "$LOG"
echo "Backup started: $(date)" >> "$LOG"
echo "Source: $SOURCE" >> "$LOG"
echo "Destination: $DEST" >> "$LOG"
echo "========================================" >> "$LOG"

rsync -avz --delete --exclude-from="$EXCLUDE" "$SOURCE" "$DEST" >> "$LOG" 2>&1

if [ $? -eq 0 ]; then
  echo "Backup completed successfully: $(date)" >> "$LOG"
else
  echo "Backup FAILED: $(date)" >> "$LOG"
  exit 1
fi

### Best Practice 10: Security Considerations

# 1. Use SSH keys with passphrases (for automation, use ssh-agent)
ssh-keygen -t ed25519 -C "backup-automation"
# Enter strong passphrase

# 2. Limit SSH key to specific command (in ~/.ssh/authorized_keys on server)
command="rsync --server --daemon ." ssh-ed25519 AAAA...

# 3. Use dedicated backup user with limited permissions
sudo useradd -m -s /bin/bash backupuser
# Grant only necessary permissions

# 4. Encrypt sensitive data before transfer
tar czf - /sensitive-data/ | openssl enc -aes-256-cbc -salt | \
  ssh user@remote-server 'cat > /backups/encrypted-backup.tar.gz.enc'

# 5. Use VPN or private network for rsync transfers
rsync -avz /data/ user@internal-backup-server:/backups/
# Don't expose rsync to public internet

# 6. Enable detailed logging for audit trails
rsync -avz --log-file=/var/log/rsync-detailed.log /source/ /destination/

# 7. Regular security audits
# Review who has access to backup servers
# Check SSH key permissions
# Monitor backup logs for anomalies

---

## 11. Troubleshooting Common Issues

### Issue 1: Permission Denied

Error:
rsync: mkstemp "/dest/file.txt.XXXXXX" failed: Permission denied (13)

Solutions:
# Check destination permissions
ssh user@remote-server "ls -ld /dest/"

# Ensure destination directory exists
ssh user@remote-server "mkdir -p /dest/"

# Fix permissions
ssh user@remote-server "chmod 755 /dest/"

# Use sudo on remote side (if you have sudo access)
rsync -avz /source/ user@remote-server:/dest/ \
  --rsync-path="sudo rsync"

### Issue 2: Connection Timeout

Error:
ssh: connect to host remote-server port 22: Connection timed out
rsync: connection unexpectedly closed (0 bytes received so far) [sender]

Solutions:
# Test SSH connection first
ssh user@remote-server
# If this fails, rsync will also fail

# Check firewall
sudo iptables -L | grep 22

# Try different port (if SSH is on non-standard port)
rsync -avz -e 'ssh -p 2222' /source/ user@remote-server:/dest/

# Increase timeout
rsync -avz --timeout=600 --contimeout=60 /source/ user@remote-server:/dest/

### Issue 3: Disk Space Full

Error:
rsync: write failed on "/dest/file.txt": No space left on device (28)

Solutions:
# Check disk space on destination
ssh user@remote-server "df -h /dest/"

# Check available inodes
ssh user@remote-server "df -i /dest/"

# Clean up old backups
ssh user@remote-server "rm -rf /dest/old-backups/"

# Use --max-size to skip large files temporarily
rsync -avz --max-size='100M' /source/ user@remote-server:/dest/

### Issue 4: Slow Transfer Speed

Problem: rsync is too slow

Solutions:
# 1. Disable compression if bandwidth is not issue
rsync -av /source/ user@remote-server:/dest/
# (without -z, faster if bandwidth is good)

# 2. Adjust compression level
rsync -avz --compress-level=3 /source/ user@remote-server:/dest/
# Levels: 1 (fast, less compression) to 9 (slow, more compression)

# 3. Use --whole-file (skip delta algorithm)
rsync -av --whole-file /source/ user@remote-server:/dest/
# Faster for small files or if most files are new

# 4. Parallel rsync (split into chunks)
# Terminal 1:
rsync -avz /source/dir1/ user@remote-server:/dest/dir1/ &
# Terminal 2:
rsync -avz /source/dir2/ user@remote-server:/dest/dir2/ &

# 5. Check network speed
ping remote-server
iperf3 -c remote-server  # If iperf3 is installed

### Issue 5: Files Not Syncing

Problem: rsync completes but files still different

Solution:
# Use --itemize-changes to see what's happening
rsync -avz --itemize-changes /source/ /dest/

# Force checksum comparison
rsync -avz --checksum /source/ /dest/

# Check for hidden characters in filenames
ls -la /source/
ls -la /dest/

# Verify timestamps
stat /source/file.txt
stat /dest/file.txt

### Issue 6: Too Many Files

Error:
rsync: send_files failed to open "/source/file.txt": Too many open files (24)

Solution:
# Increase file descriptor limit
ulimit -n 4096

# Make permanent (add to /etc/security/limits.conf):
* soft nofile 4096
* hard nofile 8192

# Batch processing (process in chunks)
find /source/ -type f | split -l 1000 - files-
for batch in files-*; do
  rsync -avz --files-from="$batch" / user@remote-server:/dest/
done

---

## 12. rsync vs Other Tools Comparison

| Feature | rsync | scp | ftp | cp | tar+ssh |
|---------|-------|-----|-----|----|---------| 
| Delta Transfer | ✅ Yes | ❌ No | ❌ No | ❌ No | ❌ No |
| Resume Capability | ✅ Yes | ❌ No | ✅ Yes | N/A | ❌ No |
| Encryption | ✅ SSH | ✅ SSH | ❌ No* | N/A | ✅ SSH |
| Compression | ✅ Yes | ✅ Yes | ✅ Yes | N/A | ✅ Yes |
| Preserves Permissions | ✅ Yes | ✅ Yes | ❌ No | ✅ Yes | ✅ Yes |
| Bandwidth Limiting | ✅ Yes | ✅ Yes | ✅ Yes | N/A | ❌ No |
| Incremental Backup | ✅ Yes | ❌ No | ❌ No | ❌ No | ❌ No |
| Directory Sync | ✅ Yes | ✅ Yes | ✅ Yes | ✅ Yes | ✅ Yes |
| Speed (Changed Files) | ⚡⚡⚡⚡⚡ | ⚡ | ⚡⚡ | ⚡⚡⚡⚡⚡ | ⚡⚡ |
| Speed (New Files) | ⚡⚡⚡⚡ | ⚡⚡⚡⚡ | ⚡⚡⚡ | ⚡⚡⚡⚡⚡ | ⚡⚡⚡⚡ |

*FTPS provides encryption

### When to Use What?

Use rsync when:
- Syncing large directories regularly
- Only changed files need transfer
- Incremental backups required
- Need to preserve all file attributes
- Remote synchronization over SSH

Use scp when:
- One-time file copy
- Small number of files
- Simple, no need for advanced features
- Files are completely new (not updates)

Use ftp/sftp when:
- Working with FTP-only servers
- Interactive file browsing needed
- Legacy system compatibility

Use cp when:
- Local file copying only
- Maximum speed on same filesystem
- Simple operations

Use tar+ssh when:
- Archiving and transferring together
- Many small files (reduces overhead)
- Want single archive file

---

## 13. Quick Reference Cheat Sheet

### Most Common Commands

# Sync local directory
rsync -avzh /source/ /destination/

# Sync to remote server (push)
rsync -avzh /local/ user@remote-server:/remote/

# Sync from remote server (pull)
rsync -avzh user@remote-server:/remote/ /local/

# Mirror with deletion
rsync -avzh --delete /source/ /destination/

# Dry run (test)
rsync -avzhn /source/ /destination/

# With progress bar
rsync -avzhP /source/ /destination/

# Limit bandwidth (1000 KB/s)
rsync -avzh --bwlimit=1000 /source/ /destination/

# Exclude patterns
rsync -avzh --exclude='*.log' /source/ /destination/

# With custom SSH port
rsync -avzh -e 'ssh -p 2222' /source/ user@remote:/dest/

### Option Quick Reference

-v : verbose
-a : archive mode (preserves everything)
-z : compress
-h : human-readable
-P : progress + partial
-n : dry run (test)
-u : update (skip newer files on destination)
-r : recursive
-p : preserve permissions
-t : preserve times
-g : preserve group
-o : preserve owner
-l : copy symlinks as symlinks
--delete : delete extraneous files from destination
--exclude : exclude files/directories
--include : include files/directories
--bwlimit : bandwidth limit
--progress : show progress
--partial : keep partially transferred files
--checksum : use checksums instead of size/time

---

## 14. Conclusion

### Key Takeaways

1. **rsync is Essential**: Every sysadmin, developer, and power user should know rsync
2. **Delta Transfer**: Only changed parts of files are transferred (huge time/bandwidth savings)
3. **Versatile**: Works locally and remotely, over SSH
4. **Safe**: Test with --dry-run before actual execution
5. **Powerful**: From simple copies to complex incremental backup systems
6. **Efficient**: Much faster than alternatives for synchronization tasks

### When to Use rsync

✅ Regular backups
✅ Website deployments
✅ Server migrations
✅ Directory synchronization
✅ Mirror creation
✅ Disaster recovery
✅ Development environment sync
✅ Media library management

### Best Practices Summary

1. Always test with --dry-run first
2. Mind the trailing slashes
3. Use -a for archive mode by default
4. Log all operations
5. Monitor and alert on failures
6. Verify backups regularly
7. Use SSH keys for automation
8. Document your rsync scripts
9. Set timeouts for remote operations
10. Follow 3-2-1 backup strategy

### Learning Path

Beginner:
- Master basic syntax
- Practice local syncs
- Understand -a option

Intermediate:
- Remote syncs with SSH
- Exclude patterns
- Progress monitoring

Advanced:
- Incremental backups with --link-dest
- Automated scripts with error handling
- Complex filtering rules
- Performance tuning

Expert:
- Custom rsync wrappers
- Integration with monitoring systems
- Multi-destination syncing
- Disaster recovery automation

---

## Author Information
Based on training by: Imran Afzal
Website: www.utclisolutions.com

For more Linux tutorials and DevOps guides, visit the website!

---

## Additional Resources

### Official Documentation
- man rsync (on any Linux system)
- https://rsync.samba.org/

### Example Scripts Repository
GitHub: Search for "rsync backup scripts"

### Recommended Reading
- "Linux Backup and Recovery" by Charles Vance
- "Unix Power Tools" by Jerry Peek

### Practice Exercises

Exercise 1: Create a backup script
- Backup your home directory
- Exclude cache and temp files
- Run daily via cron
- Send email on failure

Exercise 2: Set up remote sync
- Set up SSH keys
- Sync project directory to remote server
- Test interruption and resume

Exercise 3: Incremental backup system
- Create full backup
- Create 7 daily incremental backups
- Verify each backup is accessible
- Calculate space savings

### Community Support
- Stack Overflow: Tag [rsync]
- Unix & Linux Stack Exchange
- Reddit: r/linux, r/linuxadmin

---

End of rsync Complete Guide
